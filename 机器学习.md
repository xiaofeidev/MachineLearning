# 绪论

## 引言

【机器学习】致力于研究如何通过计算的手段，利用经验来改善系统自身的性能

计算机系统中，经验通常以【数据】形式存在

机器学习所研究的主要内容，是关于在计算机上从数据中产生【模型】的算法，即【学习算法】(【模型】泛指从数据中学得的结果)

可以说机器学习是研究关于【学习算法】的学问

## 基本术语

**数据** -> 进行机器学习，要先有数据

**记录** -> 数据集中的一条记录

**数据集** -> 一组记录的集合

**(示例/样本)** -> 数据集中的每条记录是关于一个事件或对象的描述

**(属性/特征)** -> 反映事件或对象在某方面的表现或性质的事项

**属性值** -> 喵

**(属性空间/样本空间/输入空间)** -> 属性张成的空间，如将三个属性作为三个坐标轴，张成的一个三维空间

**特征向量** -> 空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个特征向量

**维数** -> 样本的属性的个数

**(学习/训练)** -> 从数据中学得模型的过程

**训练数据** -> 训练过程中使用的数据

**训练样本** -> 训练数据中的每个样本

**训练集** -> 训练样本的集合

**假设** -> 学得的模型对应了关于数据的某种潜在的规律

**(真相/真实)** -> 潜在规律本身

**学习器** -> 模型的别称，可看作学习算法在给定数据和参数空间上的实例化

**标记** -> 训练样本示例的结果信息

**样例** -> 拥有了标记信息的训练样本示例

**(标记空间/输出空间)** -> 所有标记的集合

**分类** -> 若要预测的是**离散值**(例如好瓜、坏瓜)，此类学习任务称为分类

**回归** -> 若要预测的是连续值(例如西瓜成熟度 0.95)，此类学习任务称为回归

**二分类** -> 只涉及两个类别的分类任务，称其中一个为【正类】，另一个为【反类】

**多分类** -> 涉及多个类别的分类任务

**测试** -> 学得模型后，使用其进行预测的过程

**测试样本** -> 在测试中被预测的样本

**聚类** -> 将训练集中的数据分成若干组

**簇** -> 每组称为一个簇，这些簇可能对应一些潜在的概念划分

**监督学习** -> 训练数据有标记信息，【分类】和【回归】是其代表

**无监督学习** -> 训练数据无标记信息，【聚类】是其代表

**泛化能力** -> 学得模型适用于新样本的能力，获得具有强泛化能力的模型是机器学习的目标

一般而言，训练样本越多，越有可能获得具有强泛化能力的模型

## 假设空间

【归纳】与【演绎】是科学推理的两大基本手段

【归纳】-> 从特殊到一般的【泛化】过程

【演绎】-> 从一般到特殊的【特化】过程

从样例中学习，显然是一个归纳的过程，因此亦称【归纳学习】

【归纳学习】有狭义与广义之分，广义的归纳学习大体相当于从样例中学习

狭义的归纳学习则要求从训练数据中学得概念，因此亦称[概念学习/概念形成]

概念学习中最基本的是布尔概念学习，即对[是/不是]这样可表示为[0/1]布尔值的目标概念的学习

我们可以把学习过程看作一个在所有【假设】组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设

搜索过程中可以不断删除与正例不一致的假设和与反例不一致的假设，最终将会获得与训练集一致的假设，这就是我们学得的结果

【版本空间】-> 可能有多个假设与训练集一致，即存在着一个与训练集一致的[假设集合]，称之为【版本空间】

## 归纳偏好

通过学习得到的模型对应了假设空间中的一个假设

有时会有多个与训练集一致的假设

与不同假设对应的模型在面对新样本时会产生不同的输出，此时应该采用哪一个模型(或假设)呢？

有时无法判断多个假设中哪一个更好，而一个具体的学习算法必须要产生一个模型

这时，学习算法本身的【偏好】就会起到关键的作用

譬如说有的算法喜欢[尽可能特殊]的模型，有的算法喜欢[尽可能一般]的模型

机器学习算法在学习过程中对某种类型假设的偏好，称为【归纳偏好】或简称【偏好】

**任何一个有效的机器学习算法必有其归纳偏好**，否则会无法产生确定的学习结果，学得的模型也会具有较大的随机性

【奥卡姆剃刀】是一种常用的、自然科学研究中最基本的原则

于此处，即【若有多个假设与观察一致，则选最简单的那个】，可以此为一般性的原则来引导算法确立“正确的”偏好

【奥卡姆剃刀】并非唯一可行的原则，且其本身也具有局限性，有时会很难判断哪个假设更简单

算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能

**任何学习算法，其在某些问题上表现得更好，则必然在另一些问题上表现得更差**

【没有免费午餐】定理(NFL 定理) -> **无论学习算法 a 多聪明，学习算法 b 多笨拙，他们的期望性能相同**

当然这个定理有个重要前提：所有问题出现的机会相同，或所有问题同等重要

但实际情形并非如此

我们一般只关注自己正在试图解决的具体问题，希望为它找到一个最适合的解决方案

NFL 定理最重要的寓意，是让我们清楚地认识到，脱离具体问题，空泛地谈论“什么学习算法最好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好

必须针对具体的学习问题讨论学习的算法的相对优劣

学习算法自身的归纳偏好与问题是否相配，往往会起决定性的作用

## 发展历程

略

## 应用现状

略

## 阅读材料

本节主要介绍了一些机器学习领域重要的学术会议和期刊

# 模型评估与选择

【错误率】-> 分类错误的样本数占样本总数的比例

【精度】-> 1 - 错误率

【误差】-> 学习器的实际预测输出与样本的真实输出之间的差异

【训练误差/经验误差】-> 学习器的实际预测输出与样本的真实输出之间的差异

【泛化误差】-> 学习器在新样本上的误差

我们希望得到泛化误差小的学习器

经验误差很小、在训练集上表现很好的学习器，在新样本上的表现不一定很好

我们希望得到在新样本上能表现得很好的学习器，所以应从训练样本中尽可能学出适用于所有潜在样本的普遍规律

然而，当学习器把训练样本学得太好了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这会导致泛化性能下降

这在机器学习种被称为**【过拟合】**

与过拟合相对的是**【欠拟合】**

导致过拟合最常见的原因是由于学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合多由于学习能力低下

欠拟合较容易克服，过拟合则很麻烦

过拟合是机器学习面临的关键障碍

过拟合是无法彻底避免的，只能缓解或减小其风险

不同的学习算法或不同的参数配置会产生不同的模型，机器学习中的【模型选择】问题，选择泛化误差最小的那个模型

然而我们无法直接获得泛化误差

## 评估方法

可通过实验测试来对学习器的泛化误差进行评估进而选择

这需要一个【测试集】来测试学习器对新样本的判别能力

以测试集上的【测试误差】作为泛化误差的近似

测试集应尽可能与训练集互斥(两者交集为空)

若测试样本被用作训练了，则得到的将是过于乐观的估计结果

我们只有一个包含 m 个样例的数据集 D，通过对 D 进行适当的处理，从中产生出训练集 S 和测试集 T

### 留出法

直接将数据集 D 划分为两个互斥的集合，一个作为训练集 S，一个作为测试集 T

在 S 上训练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计

在分类任务中要保持样本的类别比例相似，**保留类别比例**的采样方式通常称为**【分层采样】**

在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取(多次实验结果的)平均值作为留出法的评估结果

留出法局限性为，有时对于数据集 D，划分训练集 S 与测试集 T 的比例难以确定，常见做法是将大约 2/3 ~ 4/5 的样本用于训练，剩余样本用于测试

### 交叉验证法

先将数据集 D 划分为 k 个大小相似的互斥子集(尽可能保持数据分布的一致性，即从 D 中通过分层采样得到)，然后每次用 k - 1 个自己的并集作为训练集，余下的单个自己作为测试集

然后进行 k 次训练和测试，最终返回的是这 k 个测试结果的平均值

由于 k 的取值很关键，又称为【k 折交叉验证】

k 最常用的取值是 10，其他常用 k 值有 5，20 等

为减小因样本划分不同而引入的差别，k 折交叉验证通常要随机使用不同的划分重复 p 次，最终结果是这 p 次结果的均值，如常见的 10 次 10 折交叉验证

【留一法】-> 若令 k = m，则得到了交叉验证法的一个特例：留一法，留一法不受随机样本划分方式的影响，因为显然这样的话划分方式是唯一的

留一法的缺陷是在数据集较大时计算开销可能是难以承受的，而且留一法的估计结果也未必永远比其他评估方法准确

### 自助法

我们希望评估的是用 D 训练出的模型，但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比 D 小，而留一法计算复杂度又太高了

【自助法】就是一种既可以减少训练样本规模不同造成的影响，同时还能高效进行试验估计的方法

它直接以【自助采样法】为基础，给定包含 m 个样本的数据集 D，我们对它进行采样产生数据集 D'，

每次随机从 D 中挑选一个样本，将其拷贝放入 D‘，然后再将该样本放回初始数据集 D 中，使得该样本在下次采样时仍有可能被采到，重复 m 次后我们就得到了包含 m 个样本的数据集 D’，此即为自助采样的结果

D 中有一部分样本会在 D‘ 中多次出现，而另一部分样本不会出现

可求得，某个样本在 m 次采样中始终不被采到的概率为 1/e，约等于 0.368

也即通过自助采样，D 中约有 36.8% 的样本未出现在 D’ 中

我们可将 D‘ 用作训练集，D - D’ 用作测试集

如此，实际评估的模型与期望评估的模型都使用 m 个训练样本，而我们仍有数据总量约 1/3 的、没在训练集中出现的样本用于测试

这样的测试结果，称为【外包估计】

自助法在数据集较小，难以有效划分训练/测试集时很有用，而在初始数据量足够时，留出法和交叉验证法更常用一些

### 调参与最终模型

大多数学习算法都有些【参数】需要设定，参数配置不同，学得模型的性能不同

对算法参数进行设定，就是通常所说的【参数调节】或简称【调参】

学习算法的很多参数是在实数范围内取值，对每种参数配置都训练出模型来是不可行的

对每个参数选定一个范围和变化步长

例如在[0, 0.2]范围内以 0.05 为步长，则实际要评估的候选参数值有 5 个

这是在计算开销和性能估计之间进行折中的结果，通过这个折中，学习过程才变得可行

即便这样折中后，调参往往仍很困难

很多强大的学习算法有大量参数需设定，这将导致极大的调参工程量

在模型选择完成后，学习算法和参数配置已选定，此时应用完整的数据集 D 重新训练模型，这才是我们最终的模型

把学得模型在实际使用中遇到的数据称为测试数据

模型评估与选择种用于评估测试的数据集常称为【验证集】

用【测试集】(生产环境)上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分为【训练集】和【验证集】，基于【验证集】上的性能来进行模型选择和调参

## 性能度量
