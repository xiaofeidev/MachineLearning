# 绪论

## 引言

【机器学习】致力于研究如何通过计算的手段，利用经验来改善系统自身的性能

计算机系统中，经验通常以【数据】形式存在

机器学习所研究的主要内容，是关于在计算机上从数据中产生【模型】的算法，即【学习算法】(【模型】泛指从数据中学得的结果)

可以说机器学习是研究关于【学习算法】的学问

## 基本术语

**数据** -> 进行机器学习，要先有数据

**记录** -> 数据集中的一条记录

**数据集** -> 一组记录的集合

**(示例/样本)** -> 数据集中的每条记录是关于一个事件或对象的描述

**(属性/特征)** -> 反映事件或对象在某方面的表现或性质的事项

**属性值** -> 喵

**(属性空间/样本空间/输入空间)** -> 属性张成的空间，如将三个属性作为三个坐标轴，张成的一个三维空间

**特征向量** -> 空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个特征向量

**维数** -> 样本的属性的个数

**(学习/训练)** -> 从数据中学得模型的过程

**训练数据** -> 训练过程中使用的数据

**训练样本** -> 训练数据中的每个样本

**训练集** -> 训练样本的集合

**假设** -> 学得的模型对应了关于数据的某种潜在的规律

**(真相/真实)** -> 潜在规律本身

**学习器** -> 模型的别称，可看作学习算法在给定数据和参数空间上的实例化

**标记** -> 训练样本示例的结果信息

**样例** -> 拥有了标记信息的训练样本示例

**(标记空间/输出空间)** -> 所有标记的集合

**分类** -> 若要预测的是**离散值**(例如好瓜、坏瓜)，此类学习任务称为分类

**回归** -> 若要预测的是连续值(例如西瓜成熟度 0.95)，此类学习任务称为回归

**二分类** -> 只涉及两个类别的分类任务，称其中一个为【正类】，另一个为【反类】

**多分类** -> 涉及多个类别的分类任务

**测试** -> 学得模型后，使用其进行预测的过程

**测试样本** -> 在测试中被预测的样本

**聚类** -> 将训练集中的数据分成若干组

**簇** -> 每组称为一个簇，这些簇可能对应一些潜在的概念划分

**监督学习** -> 训练数据有标记信息，【分类】和【回归】是其代表

**无监督学习** -> 训练数据无标记信息，【聚类】是其代表

**泛化能力** -> 学得模型适用于新样本的能力，获得具有强泛化能力的模型是机器学习的目标

一般而言，训练样本越多，越有可能获得具有强泛化能力的模型

## 假设空间

【归纳】与【演绎】是科学推理的两大基本手段

【归纳】-> 从特殊到一般的【泛化】过程

【演绎】-> 从一般到特殊的【特化】过程

从样例中学习，显然是一个归纳的过程，因此亦称【归纳学习】

【归纳学习】有狭义与广义之分，广义的归纳学习大体相当于从样例中学习

狭义的归纳学习则要求从训练数据中学得概念，因此亦称[概念学习/概念形成]

概念学习中最基本的是布尔概念学习，即对[是/不是]这样可表示为[0/1]布尔值的目标概念的学习

我们可以把学习过程看作一个在所有【假设】组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设

搜索过程中可以不断删除与正例不一致的假设和与反例不一致的假设，最终将会获得与训练集一致的假设，这就是我们学得的结果

【版本空间】-> 可能有多个假设与训练集一致，即存在着一个与训练集一致的[假设集合]，称之为【版本空间】

## 归纳偏好

通过学习得到的模型对应了假设空间中的一个假设

有时会有多个与训练集一致的假设

与不同假设对应的模型在面对新样本时会产生不同的输出，此时应该采用哪一个模型(或假设)呢？

有时无法判断多个假设中哪一个更好，而一个具体的学习算法必须要产生一个模型

这时，学习算法本身的【偏好】就会起到关键的作用

譬如说有的算法喜欢[尽可能特殊]的模型，有的算法喜欢[尽可能一般]的模型

机器学习算法在学习过程中对某种类型假设的偏好，称为【归纳偏好】或简称【偏好】

**任何一个有效的机器学习算法必有其归纳偏好**，否则会无法产生确定的学习结果，学得的模型也会具有较大的随机性

【奥卡姆剃刀】是一种常用的、自然科学研究中最基本的原则

于此处，即【若有多个假设与观察一致，则选最简单的那个】，可以此为一般性的原则来引导算法确立“正确的”偏好

【奥卡姆剃刀】并非唯一可行的原则，且其本身也具有局限性，有时会很难判断哪个假设更简单

算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能

**任何学习算法，其在某些问题上表现得更好，则必然在另一些问题上表现得更差**

【没有免费午餐】定理(NFL 定理) -> **无论学习算法 a 多聪明，学习算法 b 多笨拙，他们的期望性能相同**

当然这个定理有个重要前提：所有问题出现的机会相同，或所有问题同等重要

但实际情形并非如此

我们一般只关注自己正在试图解决的具体问题，希望为它找到一个最适合的解决方案

NFL 定理最重要的寓意，是让我们清楚地认识到，脱离具体问题，空泛地谈论“什么学习算法最好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好

必须针对具体的学习问题讨论学习的算法的相对优劣

学习算法自身的归纳偏好与问题是否相配，往往会起决定性的作用

## 发展历程

略

## 应用现状

略

## 阅读材料

本节主要介绍了一些机器学习领域重要的学术会议和期刊

# 模型评估与选择

【错误率】-> 分类错误的样本数占样本总数的比例

【精度】-> 1 - 错误率

【误差】-> 学习器的实际预测输出与样本的真实输出之间的差异

【训练误差/经验误差】-> 学习器的实际预测输出与样本的真实输出之间的差异

【泛化误差】-> 学习器在新样本上的误差

我们希望得到泛化误差小的学习器

经验误差很小、在训练集上表现很好的学习器，在新样本上的表现不一定很好

我们希望得到在新样本上能表现得很好的学习器，所以应从训练样本中尽可能学出适用于所有潜在样本的普遍规律

然而，当学习器把训练样本学得太好了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这会导致泛化性能下降

这在机器学习种被称为**【过拟合】**

与过拟合相对的是**【欠拟合】**

导致过拟合最常见的原因是由于学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合多由于学习能力低下

欠拟合较容易克服，过拟合则很麻烦

过拟合是机器学习面临的关键障碍

过拟合是无法彻底避免的，只能缓解或减小其风险

不同的学习算法或不同的参数配置会产生不同的模型，机器学习中的【模型选择】问题，选择泛化误差最小的那个模型

然而我们无法直接获得泛化误差

## 评估方法

可通过实验测试来对学习器的泛化误差进行评估进而选择

这需要一个【测试集】来测试学习器对新样本的判别能力

以测试集上的【测试误差】作为泛化误差的近似

测试集应尽可能与训练集互斥(两者交集为空)

若测试样本被用作训练了，则得到的将是过于乐观的估计结果

我们只有一个包含 m 个样例的数据集 D，通过对 D 进行适当的处理，从中产生出训练集 S 和测试集 T

### 留出法

直接将数据集 D 划分为两个互斥的集合，一个作为训练集 S，一个作为测试集 T

在 S 上训练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计

在分类任务中要保持样本的类别比例相似，**保留类别比例**的采样方式通常称为**【分层采样】**

在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取(多次实验结果的)平均值作为留出法的评估结果

留出法局限性为，有时对于数据集 D，划分训练集 S 与测试集 T 的比例难以确定，常见做法是将大约 2/3 ~ 4/5 的样本用于训练，剩余样本用于测试

### 交叉验证法

先将数据集 D 划分为 k 个大小相似的互斥子集(尽可能保持数据分布的一致性，即从 D 中通过分层采样得到)，然后每次用 k - 1 个自己的并集作为训练集，余下的单个自己作为测试集

然后进行 k 次训练和测试，最终返回的是这 k 个测试结果的平均值

由于 k 的取值很关键，又称为【k 折交叉验证】

k 最常用的取值是 10，其他常用 k 值有 5，20 等

为减小因样本划分不同而引入的差别，k 折交叉验证通常要随机使用不同的划分重复 p 次，最终结果是这 p 次结果的均值，如常见的 10 次 10 折交叉验证

【留一法】-> 若令 k = m，则得到了交叉验证法的一个特例：留一法，留一法不受随机样本划分方式的影响，因为显然这样的话划分方式是唯一的

留一法的缺陷是在数据集较大时计算开销可能是难以承受的，而且留一法的估计结果也未必永远比其他评估方法准确

### 自助法

我们希望评估的是用 D 训练出的模型，但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比 D 小，而留一法计算复杂度又太高了

【自助法】就是一种既可以减少训练样本规模不同造成的影响，同时还能高效进行试验估计的方法

它直接以【自助采样法】为基础，给定包含 m 个样本的数据集 D，我们对它进行采样产生数据集 D'，

每次随机从 D 中挑选一个样本，将其拷贝放入 D‘，然后再将该样本放回初始数据集 D 中，使得该样本在下次采样时仍有可能被采到，重复 m 次后我们就得到了包含 m 个样本的数据集 D’，此即为自助采样的结果

D 中有一部分样本会在 D‘ 中多次出现，而另一部分样本不会出现

可求得，某个样本在 m 次采样中始终不被采到的概率为 1/e，约等于 0.368

也即通过自助采样，D 中约有 36.8% 的样本未出现在 D’ 中

我们可将 D‘ 用作训练集，D - D’ 用作测试集

如此，实际评估的模型与期望评估的模型都使用 m 个训练样本，而我们仍有数据总量约 1/3 的、没在训练集中出现的样本用于测试

这样的测试结果，称为【外包估计】

自助法在数据集较小，难以有效划分训练/测试集时很有用，而在初始数据量足够时，留出法和交叉验证法更常用一些

### 调参与最终模型

大多数学习算法都有些【参数】需要设定，参数配置不同，学得模型的性能不同

对算法参数进行设定，就是通常所说的【参数调节】或简称【调参】

学习算法的很多参数是在实数范围内取值，对每种参数配置都训练出模型来是不可行的

对每个参数选定一个范围和变化步长

例如在[0, 0.2]范围内以 0.05 为步长，则实际要评估的候选参数值有 5 个

这是在计算开销和性能估计之间进行折中的结果，通过这个折中，学习过程才变得可行

即便这样折中后，调参往往仍很困难

很多强大的学习算法有大量参数需设定，这将导致极大的调参工程量

在模型选择完成后，学习算法和参数配置已选定，此时应用完整的数据集 D 重新训练模型，这才是我们最终的模型

把学得模型在实际使用中遇到的数据称为测试数据

模型评估与选择种用于评估测试的数据集常称为【验证集】

用【测试集】(生产环境)上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分为【训练集】和【验证集】，基于【验证集】上的性能来进行模型选择和调参

## 性能度量

对学习器的泛化性能进行评估

不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的**评价标准**，即【**性能度量**】

性能度量反映了任务需求，模型好坏是相对的，不仅取决于算法和数据，还决定于任务需求

回归任务最常用的性能度量是【均方误差】

下面主要介绍分类任务中常用的性能度量

### 错误率与精度

【错误率】和【精度】是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务

【错误率】-> 分类错误的样本数占样本总数的比例

【精度】-> 分类正确的样本数占样本总数的比例

精度 = 1 - 错误率

### 查准率、查全率与 F1

【真正例/TP(true positive)】【假正例/FP(false positive)】【真反例/TN(true negative)】【假反例/FN(false negative)】

**表**(分类结果混淆矩阵)：

![image-20230926175029347](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230926175029347.png)

**查准率** P = TP/(TP+FP)

**查全率** R = TP/(TP+FN)

查准率和查全率是一对矛盾的度量，即两者会此高彼低，有时要根据实际任务需要做取舍，通常只在一些简单任务中，才可能使两者都高

可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在最后的则是学习器认为最不可能是正例的样本

按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率

以查准率为纵轴、查全率为横轴作图，就得到了【查准率-查全率曲线】，简称 P-R 曲线，显示该曲线的图称为 P-R 图

> 注意在构建 P-R 曲线的过程中，不需要对每个样本再次进行模型的预测，只需要逐个假设每个样本为正例，而不管其是否真的是正例。这个过程是为了衡量模型在不同样本被假设为正例的情况下的查准率和查全率，以便构建 P-R 曲线。每个样本被假设为正例时，只需使用模型之前的预测结果和真实标签来计算查准率和查全率，而不需要重新预测。这种方式帮助我们了解模型如何在不同情况下表现，特别是在不同阈值下的性能。

P-R 曲线和 P-R 图是用于评估二分类机器学习模型性能的重要工具

P-R 曲线与平衡点示意图：

![image-20230929115316353](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929115316353.png)

通常情况下，P-R 曲线下方的面积（即曲线下积分）越大，模型性能越好。这个面积被称为平均精度，它在一定程度上表征了学习器在查准率和查全率上取得相对双高的比例，但这个值不太容易估算

因此有了其他综合考虑查准率、查全率的性能度量

【平衡点/BEP】就是这样一个度量，它是查准率=查全率时的取值

而更常用的是【F1 度量】

F1 = 2 x p x R / (P + R) = 2 x TP / (样例总数 + TP - TN)

在具体应用中，对查准率和查全率的重视程度有所不同

如在商品推荐系统中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，此时查准率更重要；而在逃犯信息检索系统中，更希望尽可能少漏掉逃犯，此时查全率更重要

F1 度量的一般形式：Fβ，能让我们表达出对查准率/查全率的不同偏好

Fβ = (1 + β^2) x P x R / ((β^2 x P) + R)

β > 0 度量了查全率对查准率的相对重要性

β = 1 时退化为标准的 F1；β > 1 时查全率有更大影响；β < 1 时查准率有更大影响

【多个二分类混淆矩阵的情况待补充】

### ROC 与 AUC

【待补充】

### 代价敏感错误率与代价曲线

【待补充】

## 比较检验

【待补充】

## 偏差与方差

【待补充】

## 阅读材料

【待补充】

# 线性模型

【待补充】

# 决策树

【待补充】

# 神经网络

## 神经元模型

> 神经网络是由具有适应性的**简单单元**组成的广泛并行互连网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应

机器学习中谈论神经网络时指的是【神经网络学习】

神经网络中最基本的成分是【神经元】模型，即上述定义中的【简单单元】

> 在生物神经网络中，每个神经元与其他神经元相连，当它【兴奋】时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个【阈值】，那么它就会被激活，即【兴奋】起来，向其他神经元发送化学物质

将上述情形抽象为简单的【M-P 神经元模型】：

![image-20230929143011063](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929143011063.png)

在这个模型中，神经元接收到来自 n 个其他神经元传递过来的输入信号，这些输入信号通过带【权重】的连接进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过【激活函数】处理以产生神经元的输出

最简单常见的**神经元激活函数**有

**阶跃函数**：

![image-20230929143933040](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929143933040.png)

阶跃函数具有不连续、不光滑等不太好的性质

**Sigmoid 函数**：

![image-20230929144216033](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929144216033.png)

此激活函数更常用，其把可能在较大范围内变化的输入值挤压到 (0,1) 输出范围内，也称挤压函数

把多个上面提到的神经元按一定的层次结构连接起来，就得到了**神经网络**

从计算机科学角度看，我们先不管神经网络是否真的模拟了生物神经网络，只需将其视为包含了许多参数的数学模型，这个模型是若干个函数相互嵌套代入而得

## 感知机与多层网络

感知机由两层神经元组成：

![image-20230929150301593](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929150301593.png)

输入层接收外界输入信号后传递给输出层，输出层是 M-P 神经元，亦称【阈值逻辑单元】

感知机能容易地实现逻辑与、或、非运算，

**感知机中的权重和阈值均可通过学习得到**

阈值可看作一个固定输入为 -1.0 的哑结点所对应的权重，这样权重和阈值的学习就可统一为权重的学习

感知机的学习规则非常简单，对训练样例 (x, y)，若当前感知机的输出为 y‘，则感知机权重 w 将这样调整

Δw = λ(y - y')x

w = w + Δw

其中 λ∈(0, 1) 称为【学习率】，可看出，若感知机对训练样例 (x, y) 预测正确，即 y’ = y，则感知机不发生变化，否则将根据错误的程度进行权重调整

感知机只有输出层神经元进行激活函数处理，即**只拥有一层功能神经元**，其学习能力非常有限

感知机只能解决**线性可分**问题(感知机的学习过程一定会收敛)，而不能解决非线性可分问题(感知机的学习过程将发生振荡，权重参数难以稳定下来)，例如异或

要解决非线性可分问题，需考虑使用多层功能神经元

输出层与输入层之间的一层神经元，被称为【隐含层】或【隐层】，隐含层和输出层神经元都是拥有激活函数的功能神经元

常见的神经网络是如下图所示的层级结构：

![image-20230929154908511](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929154908511.png)

每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接

这样的神经网络结构通常称为【多层前馈神经网络】

输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元

只需包含隐层，即可称为多层网络

神经网络的学习过程，就是根据训练数据来调整神经元之间的【权重】以及每个功能神经元的【阈值】，也即：

**神经网络学到的东西，蕴涵在权重与阈值中**

## 误差逆传播算法

多层网络的学习能力比单层感知机强得多，也需要更强大的学习算法

**误差逆传播**(error BackPropagation，简称 BP)算法就是其中最杰出的代表，这也是迄今为止最成功的神经网络学习算法

现实任务中使用神经网络时大多使用 BP 算法进行训练

BP 算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络，但【BP 网络】一般是指用 BP 算法训练的多层前馈神经网络

d 个输入，l 个输出，q 个隐层神经元的多层前馈网络结构：

![image-20230930145754670](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930145754670.png)

假设隐层和输出层神经元都使用 Sigmoid 函数

对训练例 (xk, yk)，假定神经网络的输出为：

![image-20230930150350409](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930150350409.png)

也即：

![image-20230930150607464](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930150607464.png)式 5.3

这里的 f 为 Sigmoid 激活函数

则网络在 (xk, yk) 上的均方误差为：

![image-20230930151013909](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930151013909.png)**式 5.4**

上面的神经网络图中共有 `dq + ql + q + l` 个参数需要确定

BP 是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学习规则对参数进行更新估计

任意参数 v 的更新估计式为：

v = v + Δv

下以隐层到输出层的连接权重 whj 为例进行推导

BP 算法基于【梯度下降】策略，以目标的【负梯度方向】对参数进行调整

对式 5.4 的误差 Ek，给定学习率埃塔后，有：

![image-20230930153041600](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930153041600.png)式 5.6

注意到 whj 先影响到第 j 个输出层神经元的输入值 βj，再影响到其输出值![image-20230930153852209](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930153852209.png)，

然后影响到 Ek，于是有：

![image-20230930154037220](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930154037220.png)式 5.7

(这里其实用到了复合函数求导法则)

根据 βj 的定义，显然有：

![image-20230930154207295](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930154207295.png)式 5.8

Sigmoid 函数有一个很好的性质：

f'(x) = f(x)(1 - f(x))

于是我们可以令：

![image-20230930155951555](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930155951555.png)式 5.10

综合上面各式，于是得到了 BP 算法中关于 whj 的更新公式：

![image-20230930160510794](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930160510794.png)式 5.11

类似可得：

![image-20230930160547731](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930160547731.png)式 5.12；5.13 和 5.14

上面式中的：

![image-20230930161117167](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930161117167.png)式 5.15

学习率 η ∈ (0, 1) 控制着算法每一轮迭代中的更新步长，若太大则容易振荡，太小则收敛速度又会过慢

有时为了做精细调节，可定义不同的学习率供不同层的权重参数使用

误差逆传播算法：

![image-20230930163928125](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930163928125.png)

BP 算法的目标是要最小化训练集 D 上的**【累积误差】**：

![image-20230930164403271](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930164403271.png)式 5.16

上面介绍的【标准 BP 算法】每次仅针对一个训练样例更新连接权重和阈值，也即，算法的更新规则是基于单个的 Ek 推导而得，如果类似地推导出基于累积误差最小化的更新规则，就得到了【累积误差逆传播算法】

【累积 BP 算法】与【标准 BP 算法】都很常用

一般而言，【标准 BP 算法】每次更新只针对单个样例，参数更新得非常频繁，而且对不同样例进行更新的效果可能出现【抵消】现象

为了达到同样的累积误差极小点，标准 BP 算法往往需要进行更多次数的迭代

累积 BP 算法直接针对累积误差最小化，它在读取整个训练集 D 一遍后才对参数进行更新，其参数更新的频率低得多

但通常，累积误差下降到一定程度之后，进一步下降会非常缓慢，这时标准 BP 往往会更快获得较好的解，尤其是在训练集 D 非常大时更明显

可证明，只需**【一个】**包含足够多神经元的隐层，多层前馈网络就能以任意精度逼近任意复杂度的连续函数

不过如何设置隐层神经元的个数仍是个未决问题，实际应用中通常靠【试错法】调整

正是由于其强大的表示能力，BP 神经网络经常遭遇**过拟合**，其训练误差持续降低，但测试误差却可能上升

缓解 BP 网络的过拟合的策略：

- 早停：将数据分成训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值
- 正则化：其基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权与阈值的平方和，例如可将式 5.16 改为：
  ![image-20230930185937667](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230930185937667.png)

其中 λ ∈ (0,1) 用于对经验误差与网络复杂度这两项进行折中，常通过交叉验证法来估计

## 全局最小与局部最小

若用 E 表示神经网络在训练集上的【误差】，则它显然是关于连接权 w 和阈值 θ 的函数

神经网络的训练过程可看作一个参数寻优过程，即在参数空间中，寻找一组最优参数使得 E 最小

有两种最优：

1. **局部极小**
2. **全局最小**

参数空间内梯度为零的点，只要其误差函数值小于邻点的误差函数值，就是局部极小点

可能存在多个局部极小值，但却只会有一个全局最小值

我们在参数寻优过程中是希望找到全局最小

基于梯度的搜索是使用最为广泛的参数寻优方法，此类方法中，我们从某些初始解出发，迭代寻找最优参数值，每次迭代中，我们先计算误差函数在当前点的梯度，然后根据梯度确定搜索方向

例如，由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索最优解

若误差函数在当前点的梯度为零，则已达到局部极小，更新量为零，这意味着参数的迭代更新将在此停止

如果误差函数具有多个局部极小，则不能保证找到的解是全局最小，此时称参数寻优陷入了局部极小

常采用以下策略来试图跳出局部极小，从而进一步接近全局最小：

- 以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数
- 【模拟退火】技术，模拟退火在每一步都以一定的概率接受比当前解更差的结果，从而有助于跳出局部极小(也会造成跳出全局最小)
  在每步迭代过程中，接受次优解的概率要随着时间的推移而逐渐降低，从而保证算法稳定
- 【随机梯度下降】，与标准梯度下降法精确计算梯度不同，随机梯度下降法在计算梯度时加入了随机因素
  这样即便陷入局部极小点，它计算出的梯度仍可能不为零，这样就有机会跳出局部极小继续搜索

【遗传算法】也常用来训练神经网络以更好地逼近全局最小

**上述用于跳出局部极小的技术大多是启发式，理论上尚缺乏保障(不保证一定能找到全局最小)**

## 其他常见神经网络

### RBF 网络

径向基函数网络，是一种单隐层前馈神经网络

其使用径向基函数作为隐层神经元激活函数

### ART 网络

【竞争型学习】是神经网络中一种常见的【无监督学习】策略

网络的输出神经元相互竞争，每一时刻仅有一个竞争获胜的神经元被激活，其他神经元的状态被抑制，即【胜者通吃】原则

ART(自适应谐振理论)网络是竞争型学习的重要代表

### SOM 网络

自组织映射网络是一种竞争学习型的无监督神经网络，它能将高维输入数据映射到低维空间(通常为二维)，同时保持输入数据在高维空间的拓扑结构，即将高维空间相似的样本点映射到网络输出层中的邻近神经元

### 级联相关网络

一般的神经网络模型通常假定网络结构是事先固定的，训练的目的是利用训练样本来确定合适的连接权、阈值等参数

与此不同，结构自适应网络则将网络结构也当作学习的目标之一，并希望能在训练过程中找到最符合数据特点的网络结构

级联相关网络是其重要代表

### Elman 网络

与【前馈神经网络】不同，【递归神经网络】(RNN)允许网络中出现环状结构，从而可让一些神经元的输出反馈回来作为输入信号

Elman 网络是最常用的递归神经网络之一

### Boltzmann 机

神经网络中有一类模型是为网络状态定义一个【能量】，能量最小化时网络达到理想状态，而网络的训练就是在最小化这个能量函数

## 深度学习

理论上讲，参数越多的模型复杂度越高、容量越大，这意味着其能完成更复杂的学习任务

但复杂模型的训练效率低，易陷入过拟合

而随着计算能力的大幅提高，缓解了训练低效性，训练数据的大幅增加则可降低过拟合风险

以深度学习为代表的复杂模型因而受到人们关注

深度学习模型就是很深层的神经网络

对神经网络模型，提高容量的一个简单办法是增加隐层的数目

隐层多了，相应的神经元连接权、阈值等参数就会更多

模型复杂度也可通过单纯增加隐层神经元的数目来实现

单隐层的多层前馈网络已具有很强大的学习能力，但从增加模型复杂度的角度来看，增加隐层的数目显然比增加隐层神经元的数目更有效，因为增加隐层数不仅增加了拥有激活函数的神经元数目，还**增加了激活函数嵌套的层数**

多隐层神经网络难以直接用经典算法(如标准 BP 算法)进行训练，因为误差在多隐层内逆传播时，往往会发散而不能收敛到稳定状态

【无监督逐层训练】是多隐层网络训练的有效手段

其基本思想是每次训练一层隐结点，训练时将上一层隐结点的输出作为输入，而本层隐结点的输出作为下一层隐结点的输入，这称为**【预训练】**(pre-training)；在预训练全部完成后，再对整个网络进行**【微调】**(fine-tuning)训练

例如深度信念网络(DBN)

【预训练+微调】的做法可视为将大量参数分组，对每组先找到局部看起来比较好的设置，然后再基于这些局部较优的结果联合起来进行全局寻优

这样就在利用了模型大量参数所提供的自由度的同时，有效地节省了训练开销

【权共享】是另一种节省训练开销的策略，即让一组神经元使用相同的连接权，此策略在卷积神经网络(CNN)中发挥了重要作用

可以从另一角度来理解深度学习：

无论是 DBN 还是 CNN，其多隐层堆叠、每层对上一层的输出进行处理的机制，可看作是在对输入信号进行逐层加工，从而把初始的、与输出目标之间联系不太密切的输入表示，转化成与输出目标联系更密切的表示，使得原来仅基于最后一层输出映射难以完成的任务称为可能

也即，通过多层处理，逐渐将初始的低层特征表示转化为高层特征表示后，用简单模型即可完成复杂的分类等学习任务

由此可将深度学习理解为进行【特征学习】或【表示学习】

## 阅读材料

介绍了一些神经网络相关的书、期刊、会议

神经网络是一种难解释的【黑箱模型】，即缺乏可解释性
