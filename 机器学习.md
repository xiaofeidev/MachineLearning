# 绪论

## 引言

【机器学习】致力于研究如何通过计算的手段，利用经验来改善系统自身的性能

计算机系统中，经验通常以【数据】形式存在

机器学习所研究的主要内容，是关于在计算机上从数据中产生【模型】的算法，即【学习算法】(【模型】泛指从数据中学得的结果)

可以说机器学习是研究关于【学习算法】的学问

## 基本术语

**数据** -> 进行机器学习，要先有数据

**记录** -> 数据集中的一条记录

**数据集** -> 一组记录的集合

**(示例/样本)** -> 数据集中的每条记录是关于一个事件或对象的描述

**(属性/特征)** -> 反映事件或对象在某方面的表现或性质的事项

**属性值** -> 喵

**(属性空间/样本空间/输入空间)** -> 属性张成的空间，如将三个属性作为三个坐标轴，张成的一个三维空间

**特征向量** -> 空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个特征向量

**维数** -> 样本的属性的个数

**(学习/训练)** -> 从数据中学得模型的过程

**训练数据** -> 训练过程中使用的数据

**训练样本** -> 训练数据中的每个样本

**训练集** -> 训练样本的集合

**假设** -> 学得的模型对应了关于数据的某种潜在的规律

**(真相/真实)** -> 潜在规律本身

**学习器** -> 模型的别称，可看作学习算法在给定数据和参数空间上的实例化

**标记** -> 训练样本示例的结果信息

**样例** -> 拥有了标记信息的训练样本示例

**(标记空间/输出空间)** -> 所有标记的集合

**分类** -> 若要预测的是**离散值**(例如好瓜、坏瓜)，此类学习任务称为分类

**回归** -> 若要预测的是连续值(例如西瓜成熟度 0.95)，此类学习任务称为回归

**二分类** -> 只涉及两个类别的分类任务，称其中一个为【正类】，另一个为【反类】

**多分类** -> 涉及多个类别的分类任务

**测试** -> 学得模型后，使用其进行预测的过程

**测试样本** -> 在测试中被预测的样本

**聚类** -> 将训练集中的数据分成若干组

**簇** -> 每组称为一个簇，这些簇可能对应一些潜在的概念划分

**监督学习** -> 训练数据有标记信息，【分类】和【回归】是其代表

**无监督学习** -> 训练数据无标记信息，【聚类】是其代表

**泛化能力** -> 学得模型适用于新样本的能力，获得具有强泛化能力的模型是机器学习的目标

一般而言，训练样本越多，越有可能获得具有强泛化能力的模型

## 假设空间

【归纳】与【演绎】是科学推理的两大基本手段

【归纳】-> 从特殊到一般的【泛化】过程

【演绎】-> 从一般到特殊的【特化】过程

从样例中学习，显然是一个归纳的过程，因此亦称【归纳学习】

【归纳学习】有狭义与广义之分，广义的归纳学习大体相当于从样例中学习

狭义的归纳学习则要求从训练数据中学得概念，因此亦称[概念学习/概念形成]

概念学习中最基本的是布尔概念学习，即对[是/不是]这样可表示为[0/1]布尔值的目标概念的学习

我们可以把学习过程看作一个在所有【假设】组成的空间中进行搜索的过程，搜索目标是找到与训练集匹配的假设

搜索过程中可以不断删除与正例不一致的假设和与反例不一致的假设，最终将会获得与训练集一致的假设，这就是我们学得的结果

【版本空间】-> 可能有多个假设与训练集一致，即存在着一个与训练集一致的[假设集合]，称之为【版本空间】

## 归纳偏好

通过学习得到的模型对应了假设空间中的一个假设

有时会有多个与训练集一致的假设

与不同假设对应的模型在面对新样本时会产生不同的输出，此时应该采用哪一个模型(或假设)呢？

有时无法判断多个假设中哪一个更好，而一个具体的学习算法必须要产生一个模型

这时，学习算法本身的【偏好】就会起到关键的作用

譬如说有的算法喜欢[尽可能特殊]的模型，有的算法喜欢[尽可能一般]的模型

机器学习算法在学习过程中对某种类型假设的偏好，称为【归纳偏好】或简称【偏好】

**任何一个有效的机器学习算法必有其归纳偏好**，否则会无法产生确定的学习结果，学得的模型也会具有较大的随机性

【奥卡姆剃刀】是一种常用的、自然科学研究中最基本的原则

于此处，即【若有多个假设与观察一致，则选最简单的那个】，可以此为一般性的原则来引导算法确立“正确的”偏好

【奥卡姆剃刀】并非唯一可行的原则，且其本身也具有局限性，有时会很难判断哪个假设更简单

算法的归纳偏好是否与问题本身匹配，大多数时候直接决定了算法能否取得好的性能

**任何学习算法，其在某些问题上表现得更好，则必然在另一些问题上表现得更差**

【没有免费午餐】定理(NFL 定理) -> **无论学习算法 a 多聪明，学习算法 b 多笨拙，他们的期望性能相同**

当然这个定理有个重要前提：所有问题出现的机会相同，或所有问题同等重要

但实际情形并非如此

我们一般只关注自己正在试图解决的具体问题，希望为它找到一个最适合的解决方案

NFL 定理最重要的寓意，是让我们清楚地认识到，脱离具体问题，空泛地谈论“什么学习算法最好”毫无意义，因为若考虑所有潜在的问题，则所有学习算法都一样好

必须针对具体的学习问题讨论学习的算法的相对优劣

学习算法自身的归纳偏好与问题是否相配，往往会起决定性的作用

## 发展历程

略

## 应用现状

略

## 阅读材料

本节主要介绍了一些机器学习领域重要的学术会议和期刊

# 模型评估与选择

【错误率】-> 分类错误的样本数占样本总数的比例

【精度】-> 1 - 错误率

【误差】-> 学习器的实际预测输出与样本的真实输出之间的差异

【训练误差/经验误差】-> 学习器的实际预测输出与样本的真实输出之间的差异

【泛化误差】-> 学习器在新样本上的误差

我们希望得到泛化误差小的学习器

经验误差很小、在训练集上表现很好的学习器，在新样本上的表现不一定很好

我们希望得到在新样本上能表现得很好的学习器，所以应从训练样本中尽可能学出适用于所有潜在样本的普遍规律

然而，当学习器把训练样本学得太好了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这会导致泛化性能下降

这在机器学习种被称为**【过拟合】**

与过拟合相对的是**【欠拟合】**

导致过拟合最常见的原因是由于学习能力过于强大，以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合多由于学习能力低下

欠拟合较容易克服，过拟合则很麻烦

过拟合是机器学习面临的关键障碍

过拟合是无法彻底避免的，只能缓解或减小其风险

不同的学习算法或不同的参数配置会产生不同的模型，机器学习中的【模型选择】问题，选择泛化误差最小的那个模型

然而我们无法直接获得泛化误差

## 评估方法

可通过实验测试来对学习器的泛化误差进行评估进而选择

这需要一个【测试集】来测试学习器对新样本的判别能力

以测试集上的【测试误差】作为泛化误差的近似

测试集应尽可能与训练集互斥(两者交集为空)

若测试样本被用作训练了，则得到的将是过于乐观的估计结果

我们只有一个包含 m 个样例的数据集 D，通过对 D 进行适当的处理，从中产生出训练集 S 和测试集 T

### 留出法

直接将数据集 D 划分为两个互斥的集合，一个作为训练集 S，一个作为测试集 T

在 S 上训练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计

在分类任务中要保持样本的类别比例相似，**保留类别比例**的采样方式通常称为**【分层采样】**

在使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取(多次实验结果的)平均值作为留出法的评估结果

留出法局限性为，有时对于数据集 D，划分训练集 S 与测试集 T 的比例难以确定，常见做法是将大约 2/3 ~ 4/5 的样本用于训练，剩余样本用于测试

### 交叉验证法

先将数据集 D 划分为 k 个大小相似的互斥子集(尽可能保持数据分布的一致性，即从 D 中通过分层采样得到)，然后每次用 k - 1 个自己的并集作为训练集，余下的单个自己作为测试集

然后进行 k 次训练和测试，最终返回的是这 k 个测试结果的平均值

由于 k 的取值很关键，又称为【k 折交叉验证】

k 最常用的取值是 10，其他常用 k 值有 5，20 等

为减小因样本划分不同而引入的差别，k 折交叉验证通常要随机使用不同的划分重复 p 次，最终结果是这 p 次结果的均值，如常见的 10 次 10 折交叉验证

【留一法】-> 若令 k = m，则得到了交叉验证法的一个特例：留一法，留一法不受随机样本划分方式的影响，因为显然这样的话划分方式是唯一的

留一法的缺陷是在数据集较大时计算开销可能是难以承受的，而且留一法的估计结果也未必永远比其他评估方法准确

### 自助法

我们希望评估的是用 D 训练出的模型，但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比 D 小，而留一法计算复杂度又太高了

【自助法】就是一种既可以减少训练样本规模不同造成的影响，同时还能高效进行试验估计的方法

它直接以【自助采样法】为基础，给定包含 m 个样本的数据集 D，我们对它进行采样产生数据集 D'，

每次随机从 D 中挑选一个样本，将其拷贝放入 D‘，然后再将该样本放回初始数据集 D 中，使得该样本在下次采样时仍有可能被采到，重复 m 次后我们就得到了包含 m 个样本的数据集 D’，此即为自助采样的结果

D 中有一部分样本会在 D‘ 中多次出现，而另一部分样本不会出现

可求得，某个样本在 m 次采样中始终不被采到的概率为 1/e，约等于 0.368

也即通过自助采样，D 中约有 36.8% 的样本未出现在 D’ 中

我们可将 D‘ 用作训练集，D - D’ 用作测试集

如此，实际评估的模型与期望评估的模型都使用 m 个训练样本，而我们仍有数据总量约 1/3 的、没在训练集中出现的样本用于测试

这样的测试结果，称为【外包估计】

自助法在数据集较小，难以有效划分训练/测试集时很有用，而在初始数据量足够时，留出法和交叉验证法更常用一些

### 调参与最终模型

大多数学习算法都有些【参数】需要设定，参数配置不同，学得模型的性能不同

对算法参数进行设定，就是通常所说的【参数调节】或简称【调参】

学习算法的很多参数是在实数范围内取值，对每种参数配置都训练出模型来是不可行的

对每个参数选定一个范围和变化步长

例如在[0, 0.2]范围内以 0.05 为步长，则实际要评估的候选参数值有 5 个

这是在计算开销和性能估计之间进行折中的结果，通过这个折中，学习过程才变得可行

即便这样折中后，调参往往仍很困难

很多强大的学习算法有大量参数需设定，这将导致极大的调参工程量

在模型选择完成后，学习算法和参数配置已选定，此时应用完整的数据集 D 重新训练模型，这才是我们最终的模型

把学得模型在实际使用中遇到的数据称为测试数据

模型评估与选择种用于评估测试的数据集常称为【验证集】

用【测试集】(生产环境)上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分为【训练集】和【验证集】，基于【验证集】上的性能来进行模型选择和调参

## 性能度量

对学习器的泛化性能进行评估

不仅需要有效可行的实验估计方法，还需要有衡量模型泛化能力的**评价标准**，即【**性能度量**】

性能度量反映了任务需求，模型好坏是相对的，不仅取决于算法和数据，还决定于任务需求

回归任务最常用的性能度量是【均方误差】

下面主要介绍分类任务中常用的性能度量

### 错误率与精度

【错误率】和【精度】是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务

【错误率】-> 分类错误的样本数占样本总数的比例

【精度】-> 分类正确的样本数占样本总数的比例

精度 = 1 - 错误率

### 查准率、查全率与 F1

【真正例/TP(true positive)】【假正例/FP(false positive)】【真反例/TN(true negative)】【假反例/FN(false negative)】

**表**(分类结果混淆矩阵)：

![image-20230926175029347](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230926175029347.png)

**查准率** P = TP/(TP+FP)

**查全率** R = TP/(TP+FN)

查准率和查全率是一对矛盾的度量，即两者会此高彼低，有时要根据实际任务需要做取舍，通常只在一些简单任务中，才可能使两者都高

可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为最可能是正例的样本，排在最后的则是学习器认为最不可能是正例的样本

按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率

以查准率为纵轴、查全率为横轴作图，就得到了【查准率-查全率曲线】，简称 P-R 曲线，显示该曲线的图称为 P-R 图

> 注意在构建 P-R 曲线的过程中，不需要对每个样本再次进行模型的预测，只需要逐个假设每个样本为正例，而不管其是否真的是正例。这个过程是为了衡量模型在不同样本被假设为正例的情况下的查准率和查全率，以便构建 P-R 曲线。每个样本被假设为正例时，只需使用模型之前的预测结果和真实标签来计算查准率和查全率，而不需要重新预测。这种方式帮助我们了解模型如何在不同情况下表现，特别是在不同阈值下的性能。

P-R 曲线和 P-R 图是用于评估二分类机器学习模型性能的重要工具

P-R 曲线与平衡点示意图：

![image-20230929115316353](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929115316353.png)

通常情况下，P-R 曲线下方的面积（即曲线下积分）越大，模型性能越好。这个面积被称为平均精度，它在一定程度上表征了学习器在查准率和查全率上取得相对双高的比例，但这个值不太容易估算

因此有了其他综合考虑查准率、查全率的性能度量

【平衡点/BEP】就是这样一个度量，它是查准率=查全率时的取值

而更常用的是【F1 度量】

F1 = 2 x p x R / (P + R) = 2 x TP / (样例总数 + TP - TN)

在具体应用中，对查准率和查全率的重视程度有所不同

如在商品推荐系统中，为了尽可能少打扰用户，更希望推荐内容确是用户感兴趣的，此时查准率更重要；而在逃犯信息检索系统中，更希望尽可能少漏掉逃犯，此时查全率更重要

F1 度量的一般形式：Fβ，能让我们表达出对查准率/查全率的不同偏好

Fβ = (1 + β^2) x P x R / ((β^2 x P) + R)

β > 0 度量了查全率对查准率的相对重要性

β = 1 时退化为标准的 F1；β > 1 时查全率有更大影响；β < 1 时查准率有更大影响

【多个二分类混淆矩阵的情况待补充】

### ROC 与 AUC

【待补充】

### 代价敏感错误率与代价曲线

【待补充】

## 比较检验

【待补充】

## 偏差与方差

【待补充】

## 阅读材料

【待补充】

# 线性模型

【待补充】

# 决策树

【待补充】

# 神经网络

## 神经元模型

> 神经网络是由具有适应性的**简单单元**组成的广泛并行互连网络，它的组织能够模拟生物神经系统对真实世界物体所作出的交互反应

机器学习中谈论神经网络时指的是【神经网络学习】

神经网络中最基本的成分是【神经元】模型，即上述定义中的【简单单元】

> 在生物神经网络中，每个神经元与其他神经元相连，当它【兴奋】时，就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神经元的电位超过了一个【阈值】，那么它就会被激活，即【兴奋】起来，向其他神经元发送化学物质

将上述情形抽象为简单的【M-P 神经元模型】：

![image-20230929143011063](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929143011063.png)

在这个模型中，神经元接收到来自 n 个其他神经元传递过来的输入信号，这些输入信号通过带【权重】的连接进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过【激活函数】处理以产生神经元的输出

最简单常见的**神经元激活函数**有

**阶跃函数**：

![image-20230929143933040](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929143933040.png)

阶跃函数具有不连续、不光滑等不太好的性质

**Sigmoid 函数**：

![image-20230929144216033](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929144216033.png)

此激活函数更常用，其把可能在较大范围内变化的输入值挤压到 (0,1) 输出范围内，也称挤压函数

把多个上面提到的神经元按一定的层次结构连接起来，就得到了**神经网络**

从计算机科学角度看，我们先不管神经网络是否真的模拟了生物神经网络，只需将其视为包含了许多参数的数学模型，这个模型是若干个函数相互嵌套代入而得

## 感知机与多层网络

感知机由两层神经元组成：

![image-20230929150301593](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929150301593.png)

输入层接收外界输入信号后传递给输出层，输出层是 M-P 神经元，亦称【阈值逻辑单元】

感知机能容易地实现逻辑与、或、非运算，

**感知机中的权重和阈值均可通过学习得到**

阈值可看作一个固定输入为 -1.0 的哑结点所对应的权重，这样权重和阈值的学习就可统一为权重的学习

感知机的学习规则非常简单，对训练样例 (x, y)，若当前感知机的输出为 y‘，则感知机权重 w 将这样调整

Δw = λ(y - y')x

w = w + Δw

其中 λ∈(0, 1) 称为【学习率】，可看出，若感知机对训练样例 (x, y) 预测正确，即 y’ = y，则感知机不发生变化，否则将根据错误的程度进行权重调整

感知机只有输出层神经元进行激活函数处理，即**只拥有一层功能神经元**，其学习能力非常有限

感知机只能解决**线性可分**问题(感知机的学习过程一定会收敛)，而不能解决非线性可分问题(感知机的学习过程将发生振荡，权重参数难以稳定下来)，例如异或

要解决非线性可分问题，需考虑使用多层功能神经元

输出层与输入层之间的一层神经元，被称为【隐含层】或【隐层】，隐含层和输出层神经元都是拥有激活函数的功能神经元

常见的神经网络是如下图所示的层级结构：

![image-20230929154908511](%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/image-20230929154908511.png)

每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接

这样的神经网络结构通常称为【多层前馈神经网络】

输入层神经元仅是接受输入，不进行函数处理，隐层与输出层包含功能神经元

只需包含隐层，即可称为多层网络

神经网络的学习过程，就是根据训练数据来调整神经元之间的【权重】以及每个功能神经元的【阈值】，也即：

**神经网络学到的东西，蕴涵在权重与阈值中**

## 误差逆传播算法

